{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b7cfbc",
   "metadata": {},
   "source": [
    "# ML Trading System - Interaktiv Debug Notebook\n",
    "\n",
    "Detta notebook ger dig kraftfulla verktyg f√∂r att debugga och analysera ML trading systemet med visualiseringar ist√§llet f√∂r konsol-utskrifter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3bccf",
   "metadata": {},
   "source": [
    "## 1. Setup och Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√§tt FRED API nyckel och importera bibliotek\n",
    "import os\n",
    "os.environ['FRED_API_KEY'] = '8d9ad11bf6016ba0a68f2f6f56f056ba'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Konfigurera plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Setup klart!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcee45",
   "metadata": {},
   "source": [
    "## 2. Ladda och Analysera R√•data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda data och bygg features\n",
    "from src.fetch_data import fetch_sp500_from_fred\n",
    "from src.features import build_feature_set\n",
    "from src.labels import make_std_labels\n",
    "from src.config import LABEL_HORIZON\n",
    "\n",
    "print(\"üîÑ Laddar S&P 500 data...\")\n",
    "df_raw = fetch_sp500_from_fred(start=\"2000-01-01\")\n",
    "\n",
    "print(\"üîÑ Bygger features...\")\n",
    "df_features = build_feature_set(df_raw)\n",
    "\n",
    "print(\"üîÑ Skapar labels...\")\n",
    "df_labeled = make_std_labels(df_features, horizon=LABEL_HORIZON)\n",
    "\n",
    "# Feature kolumner\n",
    "exclude = {\"Date\",\"Close\",\"label\",\"fwd_return\",\"vol_h\"}\n",
    "feature_cols = [c for c in df_labeled.columns if c not in exclude]\n",
    "\n",
    "print(f\"‚úÖ Data laddad:\")\n",
    "print(f\"  - R√•data shape: {df_raw.shape}\")\n",
    "print(f\"  - Efter features: {df_features.shape}\")\n",
    "print(f\"  - Efter labels: {df_labeled.shape}\")\n",
    "print(f\"  - Antal features: {len(feature_cols)}\")\n",
    "print(f\"  - Datum range: {df_raw['Date'].min()} till {df_raw['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f1ebb",
   "metadata": {},
   "source": [
    "## 3. Data Overview Visualisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa overview plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. S&P 500 pris √∂ver tid\n",
    "axes[0,0].plot(pd.to_datetime(df_raw['Date']), df_raw['Close'], linewidth=1)\n",
    "axes[0,0].set_title('S&P 500 Pris √ñver Tid')\n",
    "axes[0,0].set_ylabel('Pris')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Label distribution\n",
    "label_counts = df_labeled['label'].value_counts()\n",
    "axes[0,1].bar(label_counts.index, label_counts.values, color=['red', 'green'])\n",
    "axes[0,1].set_title('Label Distribution')\n",
    "axes[0,1].set_xlabel('Label (0=Ned, 1=Upp)')\n",
    "axes[0,1].set_ylabel('Antal')\n",
    "for i, v in enumerate(label_counts.values):\n",
    "    axes[0,1].text(i, v + 50, str(v), ha='center')\n",
    "\n",
    "# 3. NaN m√∂nster (sample)\n",
    "nan_data = df_labeled[feature_cols + ['label']].isnull()\n",
    "sample_indices = np.linspace(0, len(nan_data)-1, 100, dtype=int)\n",
    "sns.heatmap(nan_data.iloc[sample_indices].T, ax=axes[1,0], cbar=True, \n",
    "           yticklabels=True, xticklabels=False, cmap='Reds')\n",
    "axes[1,0].set_title('NaN M√∂nster (100 samplade rader)')\n",
    "\n",
    "# 4. Feature korrelationer (sample av features)\n",
    "sample_features = feature_cols[:10] if len(feature_cols) > 10 else feature_cols\n",
    "corr_sample = df_labeled[sample_features].dropna().corr()\n",
    "sns.heatmap(corr_sample, ax=axes[1,1], cmap='coolwarm', center=0,\n",
    "           square=True, cbar=True, annot=True, fmt='.2f')\n",
    "axes[1,1].set_title(f'Feature Korrelationer (Top {len(sample_features)})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Data kvalitet:\")\n",
    "print(f\"  - Label balans: {dict(label_counts)}\")\n",
    "print(f\"  - NaN per kolumn: {df_labeled[feature_cols].isnull().sum().sum()} totalt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b21210",
   "metadata": {},
   "source": [
    "## 4. Detaljerad Feature Analys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistik\n",
    "feature_data = df_labeled[feature_cols]\n",
    "\n",
    "# Skapa statistik DataFrame\n",
    "stats = pd.DataFrame({\n",
    "    'count': feature_data.count(),\n",
    "    'mean': feature_data.mean(),\n",
    "    'std': feature_data.std(),\n",
    "    'min': feature_data.min(),\n",
    "    'max': feature_data.max(),\n",
    "    'nan_count': feature_data.isnull().sum(),\n",
    "    'nan_pct': (feature_data.isnull().sum() / len(feature_data) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"üìà FEATURE STATISTIK:\")\n",
    "display(stats.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9951d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distributions\n",
    "n_features = len(feature_cols)\n",
    "n_cols = 4\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    if i < len(axes):\n",
    "        data = feature_data[col].dropna()\n",
    "        axes[i].hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[i].set_title(f'{col}\\n(Œº={data.mean():.3f}, œÉ={data.std():.3f})')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].axvline(data.mean(), color='red', linestyle='--', alpha=0.8, label='Mean')\n",
    "\n",
    "# D√∂lj on√∂diga subplots\n",
    "for i in range(len(feature_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ff3fc",
   "metadata": {},
   "source": [
    "## 5. ML Model Debug - Single Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparera data f√∂r ML debug\n",
    "from src.model import make_mlp_bagging, fit_predict\n",
    "\n",
    "print(\"ü§ñ SINGLE MODEL TRAINING DEBUG\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Ta clean data sample\n",
    "df_clean = df_labeled.dropna(subset=feature_cols+[\"label\"])\n",
    "sample_size = min(2000, len(df_clean))\n",
    "df_sample = df_clean.head(sample_size)\n",
    "\n",
    "X = df_sample[feature_cols].values\n",
    "y = df_sample[\"label\"].values.astype(int)\n",
    "\n",
    "print(f\"üìä Sample info:\")\n",
    "print(f\"  - Sample size: {X.shape}\")\n",
    "print(f\"  - Features: {X.shape[1]}\")\n",
    "print(f\"  - Label distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "print(f\"  - Feature matrix stats: min={X.min():.3f}, max={X.max():.3f}, mean={X.mean():.3f}\")\n",
    "\n",
    "# Split train/test\n",
    "split_idx = int(0.7 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"\\nüîÑ Training model...\")\n",
    "clf = make_mlp_bagging()\n",
    "y_pred, y_proba, trained_clf = fit_predict(clf, X_train, y_train, X_test)\n",
    "\n",
    "# Ber√§kna metrics\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"‚úÖ Model tr√§nad! Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c09dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera model results\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Prediction distribution\n",
    "pred_counts = np.bincount(y_pred.astype(int))\n",
    "axes[0,0].bar(range(len(pred_counts)), pred_counts, color=['red', 'green'])\n",
    "axes[0,0].set_title(f'Predictions (Accuracy: {accuracy:.3f})')\n",
    "axes[0,0].set_xlabel('Predicted Class')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "for i, v in enumerate(pred_counts):\n",
    "    axes[0,0].text(i, v + 5, str(v), ha='center')\n",
    "\n",
    "# 2. Probability histogram\n",
    "axes[0,1].hist(y_proba, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[0,1].set_title('Prediction Probabilities')\n",
    "axes[0,1].set_xlabel('P(Class=1)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(0.5, color='red', linestyle='--', label='Decision Threshold')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=axes[1,0], cmap='Blues',\n",
    "           xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "axes[1,0].set_title('Confusion Matrix')\n",
    "\n",
    "# 4. Probability by actual class\n",
    "for actual_class in [0, 1]:\n",
    "    mask = (y_test == actual_class)\n",
    "    class_proba = y_proba[mask]\n",
    "    axes[1,1].hist(class_proba, alpha=0.6, bins=20,\n",
    "                  label=f'Actual {actual_class}', \n",
    "                  color='red' if actual_class == 0 else 'green')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].set_title('Probability Distribution by Actual Class')\n",
    "axes[1,1].set_xlabel('P(Class=1)')\n",
    "axes[1,1].axvline(0.5, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"üìä CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0 (Ned)', 'Class 1 (Upp)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478ecc1",
   "metadata": {},
   "source": [
    "## 6. Rolling Predictions Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug rolling predictions\n",
    "from src.train_predict import rolling_train_predict\n",
    "\n",
    "print(\"üîÑ ROLLING PREDICTIONS DEBUG\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Anv√§nd begr√§nsad data f√∂r snabbare debug\n",
    "max_rows = min(1000, len(df_clean))\n",
    "df_rolling_sample = df_clean.head(max_rows).reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä Rolling sample: {df_rolling_sample.shape}\")\n",
    "\n",
    "try:\n",
    "    df_pred = rolling_train_predict(df_rolling_sample, feature_cols=feature_cols)\n",
    "    \n",
    "    print(f\"‚úÖ Rolling predictions klart!\")\n",
    "    print(f\"  - Output shape: {df_pred.shape}\")\n",
    "    print(f\"  - Nya kolumner: {set(df_pred.columns) - set(df_rolling_sample.columns)}\")\n",
    "    \n",
    "    # Analysera predictions\n",
    "    if 'pred' in df_pred.columns:\n",
    "        pred_clean = df_pred.dropna(subset=['pred'])\n",
    "        pred_counts = pred_clean['pred'].value_counts()\n",
    "        print(f\"  - Prediction distribution: {dict(pred_counts)}\")\n",
    "        print(f\"  - Giltiga predictions: {len(pred_clean)} av {len(df_pred)}\")\n",
    "        \n",
    "    if 'proba' in df_pred.columns:\n",
    "        proba_clean = df_pred.dropna(subset=['proba'])\n",
    "        if len(proba_clean) > 0:\n",
    "            print(f\"  - Probability stats: min={proba_clean['proba'].min():.3f}, \"\n",
    "                  f\"max={proba_clean['proba'].max():.3f}, mean={proba_clean['proba'].mean():.3f}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR i rolling prediction: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320a9bc",
   "metadata": {},
   "source": [
    "## 7. Interaktiv Feature Explorer\n",
    "\n",
    "K√∂r cellerna nedan f√∂r att interaktivt utforska features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion f√∂r att plotta enskilda features\n",
    "def explore_feature(feature_name):\n",
    "    \"\"\"Utforska en specifik feature interaktivt.\"\"\"\n",
    "    if feature_name not in feature_cols:\n",
    "        print(f\"‚ùå Feature '{feature_name}' finns inte!\")\n",
    "        print(f\"Tillg√§ngliga: {feature_cols}\")\n",
    "        return\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Data prep\n",
    "    data_clean = df_labeled.dropna(subset=[feature_name, 'label'])\n",
    "    \n",
    "    # 1. Time series\n",
    "    axes[0].plot(range(len(data_clean)), data_clean[feature_name], linewidth=1)\n",
    "    axes[0].set_title(f'{feature_name} Time Series')\n",
    "    axes[0].set_xlabel('Time Index')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Distribution\n",
    "    axes[1].hist(data_clean[feature_name], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1].set_title(f'{feature_name} Distribution')\n",
    "    axes[1].set_xlabel('Value')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    mean_val = data_clean[feature_name].mean()\n",
    "    axes[1].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.3f}')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # 3. By Label\n",
    "    for label in [0, 1]:\n",
    "        label_data = data_clean[data_clean['label'] == label][feature_name]\n",
    "        axes[2].hist(label_data, alpha=0.6, bins=20,\n",
    "                    label=f'Label {label} (n={len(label_data)})', \n",
    "                    color='red' if label == 0 else 'green')\n",
    "    axes[2].legend()\n",
    "    axes[2].set_title(f'{feature_name} by Label')\n",
    "    axes[2].set_xlabel('Value')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistik\n",
    "    print(f\"üìä {feature_name} Statistik:\")\n",
    "    for label in [0, 1]:\n",
    "        label_data = data_clean[data_clean['label'] == label][feature_name]\n",
    "        print(f\"  Label {label}: mean={label_data.mean():.4f}, std={label_data.std():.4f}, n={len(label_data)}\")\n",
    "\n",
    "# Lista alla tillg√§ngliga features\n",
    "print(\"üîç TILLG√ÑNGLIGA FEATURES F√ñR EXPLORATION:\")\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f\"{i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1406bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exempel: Utforska en specifik feature\n",
    "# √Ñndra feature_name till den du vill unders√∂ka\n",
    "feature_to_explore = feature_cols[0] if feature_cols else \"Close\"\n",
    "explore_feature(feature_to_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea93e8",
   "metadata": {},
   "source": [
    "## 8. Sammanfattning och N√§sta Steg\n",
    "\n",
    "Detta notebook ger dig kraftfulla verktyg f√∂r ML-debugging:\n",
    "\n",
    "### ‚úÖ Vad vi kontrollerat:\n",
    "- **Data kvalitet**: shapes, NaN-m√∂nster, distributions\n",
    "- **Feature analys**: statistik, korrelationer, outliers  \n",
    "- **ML training**: model performance, predictions, probabilities\n",
    "- **Rolling predictions**: pipeline funktionalitet\n",
    "\n",
    "### üîß Debug-verktyg du nu har:\n",
    "1. **Visualiseringar** ist√§llet f√∂r konsol-utskrifter\n",
    "2. **Interaktiv feature exploration** \n",
    "3. **Model performance analysis**\n",
    "4. **Data quality checks**\n",
    "\n",
    "### üìà N√§sta steg:\n",
    "1. K√∂r `explore_feature()` f√∂r olika features\n",
    "2. Experimentera med andra model parameters\n",
    "3. Analysera feature importance\n",
    "4. Testa olika time windows f√∂r rolling predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
